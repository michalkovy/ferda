\section{Evaluation Functions of 4ft-quantifiers} \label{Evaluation_Functions}
% JR po dohode s MR ktere quantifikatory 

The association rule is the expression $\varphi \approx \psi$ where
$\varphi $ and $ \psi $  are Boolean attributes and $ \approx $ 
is the {\it 4ft-quantifier}. The rule $\varphi \approx \psi$ is true in the 
analyzed data matrix $\cal M$ if the condition related to the 4ft-quantifier
$ \approx $  is satisfied in the 4ft table $4ft(\varphi, \psi, {\cal M})$ of $\varphi $
and $\psi$ in $\cal M$; see Tab. \ref{4ft_Table_fi_psi} and Section 
\ref{Introduction}. 
Some important 4ft-quantifiers are presented below. 
We use $ a, b, c, d $ see Tab.  \ref{4ft_Table_fi_psi}.
In addition we use %$ r = a + b$, $ k = a + c $ and
%$ s = c + d$,   , $ l = b + d $
$ n = a + b+ c + d$. We also define the 
 {\em evaluation function} ${\cal F}_{\approx}$  introduced in Section \ref{Introduction}
 for each presented 4ft-quantifier $\approx$. 



The 4ft-quantifier $ \Rightarrow_{p} $ of {\it founded
implication \/} is for $ 0 < p \leq 1 $  defined in \cite{Ha:78} 
by the condition
%$$ \frac{a}{a+b} \geq p \land a \geq Base  \mbox{ .}$$
$ \frac{a}{a+b} \geq p $. 
The rule $\varphi \Rightarrow_{p}  \psi $ says that at 
least $100p$ per cent of objects of ${\cal M }$ satisfying 
$\varphi $ satisfy also $\psi$. The evaluation function $ F_{\Rightarrow_{p}}$
of $\Rightarrow_{p}$ is defined such that 
$ F_{\Rightarrow_{p}}(a,b,c,d) = \frac{a}{a+b} $, thus we write only 
$ F_{\Rightarrow_{p}}(a,b)$ instead of $ F_{\Rightarrow_{p}}(a,b,c,d)$

Remark: The 4ft-quantifier  of {\it founded implication \/} is actually 
defined by the condition $ \frac{a}{a+b} \geq p \land a \geq B $  where 
$ 0 < p \leq 1 $, and $ B > 0$. We omit the parameter $B$ because of we are 
interested in the graph of the function $ F_{\Rightarrow_{p}}(a,b)$. 
The same is  true for the additional 4ft-quantifiers  in this paper. 
 

The 4ft-quantifier $ \Rightarrow^{!}_{p, \alpha} $ of
 {\it lower critical implication} is \ for  \ $ 0 \ < \ p \leq \ 1 $ \ and \ 
 $ 0 < \alpha < 0.5$ defined in \cite{Ha:78} by the condition
%$$   \sum_{i = a}^{a + b} {a+b \choose i}
%          p^{i} (1 - p)^{a+b-i} \leq \alpha  \land  a \geq Base \mbox{ .}$$
$   \sum_{i = a}^{a + b} {a+b \choose i}
          p^{i} (1 - p)^{a+b-i} \leq \alpha $.
The rule $\varphi \Rightarrow^{!}_{p, \alpha}  \psi $ can be derived 
from the statistical binomial test (on the significance level of $ \alpha $)
of the null hypotheses $H_{0}: P(\psi | \varphi ) \leq p $ 
 against the  alternative  one  $H_{1}: P(\psi | \varphi ) > p $. 
The rule  $\varphi \Rightarrow^{!}_{p, \alpha}  \psi $ is true in the 
data matrix ${\cal M }$ exactly in those cases when $H_{0}$
is rejected by the test in favour of $H_{1}$. 
Here $ P(\psi | \varphi ) $  is  the conditional probability of the
validity  of $ \psi$  under the condition $ \varphi $.
The evaluation function $ F_{\Rightarrow^{!}_{p, \alpha}}$ % of $\Rightarrow^{!}_{p, \alpha}}$ 
is defined such that 
$ F_{\Rightarrow^{!}_{p, \alpha}}(a,b,c,d) = \sum_{i = a}^{a + b} {a+b \choose i}
          p^{i} (1 - p)^{a+b-i} $, thus we write only 
$ F_{\Rightarrow^{!}_{p, \alpha}}(a,b)$ instead of $ F_{\Rightarrow^{!}_{p, \alpha}}(a,b,c,d)$.


The 4ft-quantifier $ \Rightarrow^{?}_{p, \alpha} $ of
 {\it upper critical implication} is for  $ 0 < p \leq 1 $ and 
 $ 0 < \alpha < 0.5$ defined in \cite{Ha:78} by the condition
%$$   \sum_{i = a}^{a + b} {a+b \choose i}
%          p^{i} (1 - p)^{a+b-i} \leq \alpha  \land  a \geq Base \mbox{ .}$$
$   \sum_{i = 0}^{a} {a+b \choose i}
          p^{i} (1 - p)^{a+b-i} > \alpha $.
The rule $\varphi \Rightarrow^{!}_{p, \alpha}  \psi $ can be derived 
from the statistical binomial test (on the significance level of $ \alpha $)
of the null hypotheses $H_{0}: P(\psi | \varphi ) \geq p $ 
 against the  alternative  one  $H_{1}: P(\psi | \varphi ) < p $. 
The evaluation function $ F_{\Rightarrow^{?}_{p, \alpha}}$ % of $\Rightarrow^{!}_{p, \alpha}}$ 
is defined such that 
$ F_{\Rightarrow^{?}_{p, \alpha}}(a,b,c,d) =    \sum_{i = 0}^{a} {a+b \choose i}  p^{i} (1 - p)^{a+b-i} $
          thus we write only 
$ F_{\Rightarrow^{?}_{p, \alpha}}(a,b)$ instead of $ F_{\Rightarrow^{?}_{p, \alpha}}(a,b,c,d)$.


%\item
The 4ft-quantifier $ \equiv_{p} $ of {\it founded
equivalence \/} is for $ 0 < p \leq 1 $   
defined in \cite{Ha:83} by the condition
%$$ \frac{a+d}{n} \geq p \land a \geq Base \mbox{ .}$$
$ \frac{a+d}{n} \geq p $. 
The rule $\varphi \equiv_{p}  \psi $   means that $\varphi$ and $\psi$ have the same value (either
{\it true} or {\it false}) for at least $100p$ per cent of all
objects of ${\cal M }$. 
The evaluation function $ F_{\equiv_{p}}$
of $\equiv_{p}$ is defined such that 
$ F_{\equiv_{p}}(a,b,c,d) = \frac{a+d}{a+b+c+d} $.

The 4ft-quantifier 
$ \sim_{\delta} $ of {\it simple deviation \/} 
is for $ 0 < \delta $ defined in \cite{Ha:78} 
by the condition $ ad > e^{\delta}bc $.
The rule $\varphi \sim_{\delta}  \psi $  
can be interpreted as "the logarithmic interaction of $\varphi $ 
and $ \psi $ is estimated to be greater than $\delta$". 
The evaluation function $ F_{\sim_{\delta}}$
 is defined such that 
$ F_{\sim_{\delta}}(a,b,c,d) =  \ln(\frac{ad}{bc}) $, 
the verification condition is $ F_{\sim_{\delta}}(a,b,c,d) > \delta$.

%\item
The Fisher's quantifier $ \sim_{\alpha} $ is 
 for $ 0 < \alpha < 0.5$ defined in \cite{Ha:78} by the condition
% $$  \sum_{i = a}^{\min(a+b,a+c)} \frac{ {a+c \choose i} {a+b+c+d - i \choose a+b - i} }
%                               {{a+b+c+d \choose a+b }}  \leq \alpha \  \wedge $$
% $$  \sum_{i = a}^{\min(r,k)} \frac{ r!s!k!l!} {i!(r-i)!(k-i)!(n-r-k+i)!n!}  \leq \alpha \  \wedge $$
% $$  \sum_{i = a}^{\min(r,k)} \frac{ {k \choose i } {n - k \choose r - i } }  { {r \choose n} } \leq \alpha \  \wedge
%  \ ad > bc \ \wedge \ a \geq Base  \mbox{ .}$$
$  \sum_{i = a}^{\min(a+b,a+c)} \frac{ {a+c \choose i} {a+b+c+d - i \choose a+b - i} }
                               {{a+b+c+d \choose a+b }}  \leq \alpha \  \land ad > bc $
The rule $\varphi \sim_{\alpha}  \psi $ 
can be derived from the statistical one-sided Fisher's 
 test (on the level of $ \alpha$ ) of the null hypothesis  
$H_{0}:$  $\varphi$  and $\psi $ are independent 
 against the  alternative  one  $H_{1}: $ 
 the logarithmic interaction of $\varphi$  and $\psi $ is positive. 
The evaluation function $ F_{\sim_{\alpha}}$
of $\sim_{\alpha}$ is here defined such that 
$ F_{\sim_{\alpha}}(a,b,c,d) =  \sum_{i = a}^{\min(a+b,a+c)} \frac{ {a+c \choose i} {a+b+c+d - i \choose a+b - i} }
                               {{a+b+c+d \choose a+b }}    $  
if $ad > bc$ and 
$ F_{\sim_{\alpha}}(a,b,c,d) =  0.5 $  if $ad \leq bc$.  
The verification condition is $ F_{\sim_{\alpha}}(a,b,c,d) \leq \alpha $ (for $ 0 < \alpha < 0.5$). 

%(we do not consider the condition $ad > bc$ that can be investigated in relation to 
%the 4ft-quantifier $ \sim_{\delta} $ of simple deviation, see above).  
%
%===================RAUCH==================
%
%Holena pise, ze podminka se nesmi vypustit (viz. posudek)
%
%==========================================

%\item
The 4ft-quantifier 
$ \Rightarrow^{+}_{p} $ of {\it above average dependence \/} 
is for $ 0 < p $ defined  
in \cite{RS:05A} by the condition
%$$ \frac{a}{a+b} \geq (1+p) \frac{a+c}{a+b+c+d} \land a \geq Base \mbox{ .}$$
$ \frac{a}{a+b} \geq (1+p) \frac{a+c}{n} $.
The rule $\varphi \Rightarrow^{+}_{p}  \psi $  
means that among the objects satisfying $\varphi$ is at least
$100p$ per cent more objects satisfying $\psi$ than among all
objects. 
The evaluation function $ F_{\Rightarrow^{+}_{p}}$
of $\Rightarrow^{+}_{p}$ is defined such that 
$ F_{\Rightarrow^{+}_{p}}(a,b,c,d) =  \frac{ an} {(a+b)(a+c)} - 1$, 
the verification condition is $ F_{\Rightarrow^{+}_{p}}(a,b,c,d) =  \geq p$.


%item
%The {\it Kulczynski quantifier \/} is yet another way to measure dependency between 
%$\varphi$ and $\psi$ introduced in  \cite{Han:07}. It is defined by the condition
%$ \frac{a}{2}(\frac{1}{a+b}+\frac{1}{a+c}) \geq p$ and can be interpreted in 
%terms of conditional probabilities as arithmetic mean of 
%$P(\varphi|\psi)$ and $P(\psi|\varphi)$. We will signify the quantifier 
%$ \sim_{\kappa} $ and its evaluation function is 
%$F_{\sim_{\kappa}}(a,b,c,d) =  \frac{a}{2}(\frac{1}{a+b}+\frac{1}{a+c})$. 

%item
The last presented quantifier is the {\it pairing quantifier \/} 
$ \circ\bullet $. The quantifier was introduced in \cite{Kupka} by condition
$2\frac{a^{2}d^{2}}{a^{4}+d^{4}} \geq p$
and should measure the level of pairing of tuple of examined items. The evaluation
function for the quantifier is 
$F_{\circ\bullet}(a,b,c,d) = 2\frac{a^{2}d^{2}}{a^{4}+d^{4}}$. The function is
independent on $b$ and $c$ and can be written as $F_{\circ\bullet}(a,d)$.
